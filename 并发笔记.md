### long在32位系统不是原子性

对于32位操作系统来说，单次次操作能处理的最长长度为32bit，而long类型8字节64bit，所以对long的读写都要两条指令才能完成（即每次读写64bit中的32bit）。

### cpu流水线指令

* 取指IF
* 译码和取寄存器操作数ID
* 执行或者有效地址计算EX
* 存储器访问MEM
* 写回WB

当指令完成译码时，便可进行下一条指令的取指IF操作

### java Thread类的线程状态定义

```java
public static enum State {
    NEW,
    RUNNABLE,
    BLOCKED,
    WAITING,
    TIMED_WAITING,
    TERMINATED;

    private State() {
    }
}
```



# ReentrantLock

ReentrantLock 可重入锁(能够连续获得同一把锁)

## 公平锁与非公平锁

公平锁能够解决饥饿现象(按队列里边的先后顺序)，需要维护一个有序队列，成本高性能相对较低。

非公平锁随机指定(synchronized就是非公平锁)。

```java
//默认使用非公平锁
public ReentrantLock() {
    this.sync = new ReentrantLock.NonfairSync();
}

public ReentrantLock(boolean fair) {
    this.sync = (ReentrantLock.Sync)(fair ? new ReentrantLock.FairSync() : new ReentrantLock.NonfairSync());
}
```

## 非公平锁加锁

（1）NonfairSync.lock()

```java
/**
 * Performs lock.  Try immediate barge, backing up to normal
 * acquire on failure.
 */
final void lock() {
    //cas的操作保证原子性，将state从0->1，成功返回true，加锁成功。
    if (compareAndSetState(0, 1))
        //设置当前抢到锁的线程
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}

```

（2）AbstractQueuedSunchronizer.acquire()

```java
//短路与，没有获取成功则加入等待队列尾部
public final void acquire(int arg) {
    if (!this.tryAcquire(arg) && this.acquireQueued(this.addWaiter(AbstractQueuedSynchronizer.Node.EXCLUSIVE), arg)) {
        selfInterrupt();
    }

}
```

（3）tryAcquire()

```java
protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
}
```

（4）nonfairTryAcquire()

```java
/**
 * Performs non-fair tryLock.  tryAcquire is implemented in
 * subclasses, but both need nonfair try for trylock method.
 */
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    //获取state值
    int c = getState();
    //state=0表示当前没有线程持有锁，则使用cas尝试获取
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            //抢到了就退出
            return true;
        }
    }
    //如果state>0则表示当前锁被线程持有，则判断是不是自己持有
    else if (current == getExclusiveOwnerThread()) {
        //如果是当前线程，则重入，state+1
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

* 获取当前的state的值
* 如果state=0，表示当前没线程持有锁，则尝试获取锁（将state=0使用cas修改成1，如果成功则设置当前线程，和上面的逻辑一致）
* 如果state>0表示当前锁被线程持有，则判断持有锁的线程是不是当前线程，如果是当前线程，则state+1，这里是实现可重入锁的关键
* 否则返回false，则会将当前线程的信息生成Node节点，打入到等待队列

（5）unLock()

```java
public void unlock() {
    sync.release(1);
}
```

（6）release()

```java
protected final boolean tryRelease(int releases) {
            int c = this.getState() - releases;
            if (Thread.currentThread() != this.getExclusiveOwnerThread()) {
                throw new IllegalMonitorStateException();
            } else {
                boolean free = false;
                if (c == 0) {
                    free = true;
                    this.setExclusiveOwnerThread((Thread)null);
                }

                this.setState(c);
                return free;
            }
        }
```

* 首先将state-releases，这里如果是实现锁的情况，releases的值一般是1，这里我详细解释一下，假如线程A第一次获取锁则state=1，当线程A继续获取该锁（重入）则state+1=2，以此类推，每重入一次则加1，当释放锁的时候，则进行相应的减1，只有当全部释放完state=0时才返回true，但是如果当调用condition.await()方法则会直接将state减成0，因为要全部释放锁
* 判断当前释放锁的线程是不是持有锁的线程，如果不是则抛异常，线程A不能释放线程B持有的锁
* 当全部释放完，state=0，则将持有锁的线程变量设置成null，表示当前没有线程持有锁
* 否则返回false

## 解决死锁的方法

* **中断响应：**通过使用lockInterruptibly()加锁，使得能够响应中断
* **锁申请等待限时：**使用tryLock(number, TimeUnit.SECONDS)传入等待时间，超时返回false

## 常用的方法

* lock()：获取锁，如果锁被占用，则等待。
* lockInterruptibly()：获得锁，优先响应中断。
* tryLock()：尝试获取锁，如果成功，返回true；如果不成功过，则直接返回false(不等待)。
* tryLock(long time, TimeUnit unit)：在给定时间内尝试获取锁，超时直接返回false。
* unlock()：释放锁。

## 重入锁的实现的要素

集中在java层面

* 原子状态。通过CAS(Compare And Swap)操作存储当前锁的状态，判断锁是否被别的线程持有。
  * 通过一个int类型的state去控制锁
  * 当state=0表示当前锁没有被占有，>0表示被线程占有
  * 抢锁的过程其实就是使用cas尝试讲state=0修改成state=1，如果抢到锁，需要记录抢到锁的线程
  * 当一个线程多次获取一个锁时，是在state做累加，同时释放的话就递减
  * 释放锁就是将state=1（或者>1是递减）变成state=0，**此时不需要使用cas，因为没有竞争，锁是被当前线程持有的**，当锁完全释放，则设置当前持有锁的那个变量设置为null
* 等待队列。没有请求到锁的线程，进入等待队列等待。线程释放锁的时候，系统从等待队列唤醒一个线程工作。
  * 非公平锁是随机挑选一个进行唤醒
  * 公平锁按照有序队列先后顺序进行唤醒
* 阻塞原语。park()和upark()，用来挂起和恢复线程。没得到锁的线程就被挂起。

# Conditon条件

```java
void await() throws InterruptedException;

void awaitUninterruptibly();

long awaitNanos(long var1) throws InterruptedException;

boolean await(long var1, TimeUnit var3) throws InterruptedException;

boolean awaitUntil(Date var1) throws InterruptedException;

void signal();

void signalAll();
```

* await()使当前线程等待，同时释放当前锁。(与Object的wait()类似)

* awaitUninterruptibly()与await()相比，不会在等待时响应中断。
* singal()唤醒一个等待线程。singalAll()唤醒所有等待的线程。

# Semaphore信号量

**允许多个线程同时访问某一个资源**

```java
public Semaphore(int permits) {
    this.sync = new Semaphore.NonfairSync(permits);
}
//int permits指定信号量的准入数(同时能申请多少个许可)，boolean fair指定是否公平
public Semaphore(int permits, boolean fair) {
    this.sync = (Semaphore.Sync)(fair ? new Semaphore.FairSync(permits) : new Semaphore.NonfairSync(permits));
}
```

**主要方法**

```java
//尝试获取准入的许可，无法获得则等待，或者当前线程被中断。
public void acquire() throws InterruptedException {
    this.sync.acquireSharedInterruptibly(1);
}
//不响应中断
public void acquireUninterruptibly() {
    this.sync.acquireShared(1);
}
//尝试获得许可，失败立即返回，不等待
public boolean tryAcquire() {
    return this.sync.nonfairTryAcquireShared(1) >= 0;
}
//超时返回
public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException {
    return this.sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}
//释放许可
public void release() {
    this.sync.releaseShared(1);
}
```

# ReadWriteLock

## 为什么要使用读写分离锁

能够减少锁竞争，A1,A2,A3写操作，B1,B2,B3读操作。B1读，则B2B3等待。

读写锁允许多个线程读。实现B1,B2,B3并行。

## 约束规则

* 读-读不互斥，不阻塞
* 读-写互斥，读阻塞写，写阻塞读
* 写-写互斥，写写阻塞

# CountDownLatch倒计时器

```java
//count为传入的线程数
public CountDownLatch(int count) {
    if (count < 0) {
        throw new IllegalArgumentException("count < 0");
    } else {
        this.sync = new CountDownLatch.Sync(count);
    }
}
//每有一个线程完成任务时，
public void countDown() {
    this.sync.releaseShared(1);
}

//调用await阻塞 等待count为0(即线程完成数为10)才继续往下走
public void await() throws InterruptedException {
    this.sync.acquireSharedInterruptibly(1);
}

```

# CyclicBarrier循环栅栏

与CountDownLatch相比，计数器能够重复使用，第一批10个线程完成后，开始下一批线程的计时器倒数。

并且可以接收一个Runnable barrierAction参数，在计时器完成一次计时后执行

```java
public CyclicBarrier(int parties, Runnable barrierAction) {
    this.lock = new ReentrantLock();
    this.trip = this.lock.newCondition();
    this.generation = new CyclicBarrier.Generation();
    if (parties <= 0) {
        throw new IllegalArgumentException();
    } else {
        this.parties = parties;
        this.count = parties;
        this.barrierCommand = barrierAction;
    }
}

public CyclicBarrier(int parties) {
    this(parties, (Runnable)null);
}
```

一次计数完成后再调用public int await()会开启下一个计数

```java
//InterruptedException线程被中断的常见异常
//BrokenBarrierException表示当前的CyclicBarrier已破损(好比其中一个线程被中断)，避免其它线程进行永久无所谓的等待。
public int await() throws InterruptedException, BrokenBarrierException {
    try {
        return this.dowait(false, 0L);
    } catch (TimeoutException var2) {
        throw new Error(var2);
    }
}

public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException {
    return this.dowait(true, unit.toNanos(timeout));
}
```

# LockSupport线程阻塞工具类

* 能够在线程内任意地方让线程阻塞
* 与Thread.suspend()**(阻塞线程，但是不会放弃锁)**，弥补了先调用resume()造成的死锁问题
* 与Object.wait()相比，不用去获取某一个对象的锁，不会抛出InterruptedException异常
* 即使先调用unpark()也不会造成死锁
  * 使用了类似信号量的机制，为每一个线程准备了一个许可
    * 许可可用，立即返回，消费该许可(许可变为不可用)
    * 许可不可用，阻塞
  * unpark()使一个许可从不可用变为可用状态(一个线程在LockSupport中只能有一个许可)
  * park()不会抛出InterruptedException异常

```java
public static void unpark(Thread thread) {
    if (thread != null) {
        U.unpark(thread);
    }

}

public static void park() {
    U.park(false, 0L);
}
//为当前线程设置阻塞对象
public static void park(Object blocker) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    U.park(false, 0L);
    setBlocker(t, (Object)null);
}

public static void parkNanos(Object blocker, long nanos) {
    if (nanos > 0L) {
        Thread t = Thread.currentThread();
        setBlocker(t, blocker);
        U.park(false, nanos);
        setBlocker(t, (Object)null);
    }

}

public static void parkUntil(Object blocker, long deadline) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    U.park(true, deadline);
    setBlocker(t, (Object)null);
}
```

# 线程池

## 为什么要使用线程池

* 传统方法下创建线程，当线程运行完run()方法后就回收，当创建的线程量过大，反而会影响cpu和内存资源‘
* 创建和关闭都需要花费时间，如果每次都为一个小任务创建线程，可能会出现创建与关闭线程的时间大于线程工作的时间
* 大量线程可能会抢占线程资源，造成OutOfMemory异常。或是大量的线程回收会给GC回收带来很大的压力，延长GC的停顿时间

## 什么是线程池

* 避免频繁的创建和销毁线程，对创建的线程池进行复用。

* 创建线程->从线程池获得空闲线程
* 关闭线程->将线程归还给线程池

## 常用的构造线程池的方法

**可通过Executors快速创建一下几种线程池**

以下几种线程池都是基于ThreadPoolExecutor实现

* newFixedT和readPool()：固定大小的线程池，线程数量不变
  * 
* newSingleThreadExecutor()：单一线程池，依照队列先进先出
* newCachedThreadPool()：不固定大小的线程池，随着请求数量增加。
* newSingleThreadScheduledExecutor()：返回一个线程池大小为1的ScheduledExecutorService对象。可执行定时任务。
* newScheduledThreadPool()：返回一个ScheduledExecutorService对象，可指定线程数量
  * 不一定会立刻安排任务，在指定时间对任务进行调度
  * schedule()：指定调用调用任务
  * schduledAtFixedRate()：周期性调用任务，以上一次任务开始时间为起点，根据period参数为时间间隔调用下一次任务。
  * schduleWithFixedDelay()：周期性调用任务，以上一次任务结束时为起点，根据delay参数为时间间隔调用下一次任务。
  * 执行时间超过调度时间，则任务将在上一个任务结束后立即调用。
  * 任务遇到异常，后续所有的子任务都会停止调度。



### 可能会出现的问题

* newSingleThreadExecutor()是newFixedT和readPool()的退化，单纯将线城市数量设置为1
* newCachedThreadPool()，核心容量corePoolSize为0，maximumPoolSize为无穷大的线程池。使用SynchronousQueue(直接提交队列)队列，所以会导致总是增加线程执行任务，如果有大量的任务请求，会快速的消耗系统资源。

## 线程池内部实现

**自定义线程池ThreadPoolExecutor**

```java
public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) {
    this.ctl = new AtomicInteger(ctlOf(-536870912, 0));
    this.mainLock = new ReentrantLock();
    this.workers = new HashSet();
    this.termination = this.mainLock.newCondition();
    if (corePoolSize >= 0 && maximumPoolSize > 0 && maximumPoolSize >= corePoolSize && keepAliveTime >= 0L) {
        if (workQueue != null && threadFactory != null && handler != null) {
            this.corePoolSize = corePoolSize;
            this.maximumPoolSize = maximumPoolSize;
            this.workQueue = workQueue;
            this.keepAliveTime = unit.toNanos(keepAliveTime);
            this.threadFactory = threadFactory;
            this.handler = handler;
        } else {
            throw new NullPointerException();
        }
    } else {
        throw new IllegalArgumentException();
    }
}
```

### 常用的参数

* corePoolSize：指定了线程池中的线程数量
* maximunPoolSize：指定了线程池中最大线程数量
* keepAliveTime：当线程池数量超过corePoolzSize时，多余的空闲线程的存活时间。
* unit：keepAliveTime的单位
* workQueue：任务队列，被提交当尚未被执行的任务。
* threadFactory：线程工厂，用于创建线程，一般采用默认。
* handler：拒绝策略。任务太多来不及处理，如何拒绝任务

### workQueue队列

指提交但未被执行的任务队列，是一个额BlockingQueue接口的对象，仅用于存放Runnable对象。

在ThreadPoolExecutor的构造函数中可使用以下几种BolckingQueue

* 直接提交的队列：该功能由**SynchronousQueue**对象提供。SynchronousQueue特殊之处在于它**没有容量，每一个插入操作都要等待相应的删除操作**。使用SynchronousQueue作为队列，提交的任务不会被真实的保存，直接将新任务提交给线程执行，没有空闲的线程则尝试创建新的线程，若线程数量已达到最大值，则执行拒绝策略。所以**使用SynchronousQueue队列需要设置很大的maximunPoolSize值**。
* 有界的任务队列：可以使用**ArrayBlockingQueue**实现，构造函数必须带一个容量参数，表示该队列最大的容量。
  * 如果线程池的实际数量小于corePoolSize，则优先创建新的线程。
  * 如果大于corePoolSize，则将新任务加入等待队列。
  * 如果等待队列已满，无法加入，则在总线程不大于maximumPoolSize的前提下，创建新的线程执行任务。
  * 如果大于maximumPoolSize，则执行拒绝策略。
  * **有界的任务队列仅在任务队列装满时，才可能将线程数提升到corePoolSize以上**，也就是说总是将任务线程数保持在corePoolSize。
  * **先进先出**
* 无界的任务队列：可通过**LinkedBlockingQueue**实现。
  * 不存在入队失败的情况，队列大小与系统内存有关。
  * 新任务到来，若小于corePoolSize的大小，则创建线程执行。
  * 若大于corePoolSize的大小，则加入等待队列执行，请求越多队列增长。
  * 使用LinkedBlockingQueue的话，corePoolSize与maximumPoolSize可相等。
  * **先进先出**
* 优先任务队列：通过**PriorityBlockingQueue**实现(特殊的无界队列)，可控制任务执行的先后顺序。
  * 根据任务的优先级顺序先后执行。

## 线程池的执行过程

```java
public void execute(Runnable command) {
    if (command == null) {
        throw new NullPointerException();
    } else {
        int c = this.ctl.get();
        //判断工作的线程数是否小于核心线程数
        if (workerCountOf(c) < this.corePoolSize) {
            //通过addWorker()调度执行
            if (this.addWorker(command, true)) {
                return;
            }

            c = this.ctl.get();
        }
		//大于核心线程数，使用this.workQueue.offer(command)加入等待队列
        if (isRunning(c) && this.workQueue.offer(command)) {
            int recheck = this.ctl.get();
            if (!isRunning(recheck) && this.remove(command)) {
                this.reject(command);
            } else if (workerCountOf(recheck) == 0) {
                this.addWorker((Runnable)null, false);
            }
        } 
        //加入等待队列失败，任务直接提交给线程池，如果线程数量达到maximumPoolSize，提交失败
        else if (!this.addWorker(command, false)) {
            //执行拒绝策略
            this.reject(command);
        }

    }
}
```

任务提交---->

* **小于corePoolSize**，任务提交---->分配线程执行
* **大于corePoolSize**---->提交到等待队列
  * **成功提交**到等待队列---->等待执行
  * **失败提交**到等待队列----->提交线程池
    * 线程数量达到maximumPoolSize，**提交失败**---->拒绝执行，走拒绝策略
    * 线程数量未达到maximumPoolSize，**提交成功**---->分配线程执行

## 拒绝策略Handle

### 概念

线程池用完，等待队列也满了，启动拒绝策略。



### 内置的4种拒绝策略

```java
//都实现该接口
public interface RejectedExecutionHandler {
    void rejectedExecution(Runnable var1, ThreadPoolExecutor var2);
}
```

* AbortPolicy策略：直接抛出异常，停止系统工作。
* CallerRunsPolicy策略：当线程未关闭，直接在**调用者**的线程中，运行被丢弃的任务。
  * 可能导致性能下降
* DiscardOledestPolicy策略：将丢弃最老的一个请求，，再次尝试提交新任务。
* DiscardPolicy策略：默默丢弃无法处理的任务。

## 自定义线程创建ThreadFactory

```java
public interface ThreadFactory {
    Thread newThread(Runnable var1);
}
```

实现该接口可自定义线程(如守护线程)

## 线程池扩展

ThreadPoolExecute提供以下几种对线程池实现控制

```java
protected void beforeExecute(Thread t, Runnable r) {
}

protected void afterExecute(Runnable r, Throwable t) {
}

protected void terminated() {
}
```

## 使用submit()可能出现的问题

submit()提交任务，发生错误不会出现异常堆栈。

异常堆栈变成了submit()的返回值。需要使用Future的get()方法才能获取到异常堆栈的信息。

或是使用execute()，但其返回的值是void。

## Fork/Join框架

将大数据分割成一个个小数据在将结果合并。

业务内复杂，特殊情况下使用。

public<T> ForkJoinTask<T> submit(ForkJoinTask<T> task)

详情见《实战java高并发程序设计》p117

## 并发容器

该下述只是简单说明，详情需自己看差源码。

### 常用的并发容器

* ConcurrentHashMap：高效并发HashMap的锁升级版(区分使用分段锁与synchronized两个不同时期的ConcurrentHashMap，可能不算完全线程安全的容器)。
* CopyOnWriteArrayList：写时复制，适用于读多写少的情况
* ConcurrentLinkedQueue：高效并发队列，基于链表实现。
* BlockingQueue：阻塞队列等的上级接口。
* **ConcurrentSkipListMap：**跳表的实现。







# 锁优化

## 如何提高锁的性能

### 减小锁持有时间

降低锁冲突可能

### 减小锁的粒度

通过分割数据结构，缩小锁定对象的范围，减小锁冲突的可能

例如ConcurrentHashMap采取分段锁(后来换回synchronized)

### 读写分离替换独占锁

适用于读多写少的情况

### 锁分离

如实现BlocjingQueue接口的数据结构

take()与put()分别从队列读和写。不过一个在头一个在尾，两者不冲突。他们只需要对自己的takeLock或者putLock竞争

使用独占锁则take与put需要等待对方释放锁

### 锁粗化

像JVM会对会对一连串连续地对同一锁不断进行请求和释放的操作时，便会把所有的锁操作整合成对锁的一次请求。

## JVM对锁的改进

### 概述

JVM的锁synchronized在以前是一个重量级锁，后来不断改进引入偏向锁、轻量级锁。

通过锁升级控制。

### 偏向锁

如果一个线程获得了锁，锁则进入偏向锁模式。

当这个线程再次请求锁，不需要再去拿锁做同步。

### 轻量级锁

在竞争激烈的情况下，偏向锁会失效。

此时jvm会将偏向锁升级为轻量级锁。

将对象头部(对象头包括Mark Word， Klass Word， 数组长度)作为指针，指向持有锁的线程堆栈的内部，以此判断一个线程是否持有对象锁。	

* 线程获取轻量级锁成功，则顺利进入临界区。
* 线程获取轻量级锁失败，则其他线程先获得了轻量级锁，此时当前线程的锁请求会**升级为重量级锁**。

### 对象头放于锁.md中



![对象结构图](\images\对象结构图.png)



### 自旋锁

锁膨胀后，虚拟机为避免线程真实的在操作系统层面挂起，默认是10次，当中没获取锁成功才真正的挂起

### 锁消除

JVM在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，以此节省无意义的时间。

锁消除需要开启逃逸分析(观察一个变量是否会逃出作用域)。

逃逸分析需在-server模式下进行，可使用-XX:+DoEscapeAnalysis开启逃逸分析。

再通过-XX:+EliminateLocks开启锁消除

## ThreadLocal

### 概述

线程的局部变量，线程私有，所以是线程安全的。

```java
//存放用户信息的ThreadLocal
private static final ThreadLocal<UserInfo> userInfoThreadLocal = new ThreadLocal<>();

public Response handleRequest(UserInfo userInfo) {
  Response response = new Response();
  try {
    // 1.用户信息set到线程局部变量中
    userInfoThreadLocal.set(userInfo);
    doHandle();
  } finally {
    // 3.使用完移除掉
    userInfoThreadLocal.remove();
  }

  return response;
}
    
//业务逻辑处理
private void doHandle () {
  // 2.实际用的时候取出来
  UserInfo userInfo = userInfoThreadLocal.get();
  //查询用户资产
  queryUserAsset(userInfo);
}


```

* 首先我们通过`ThreadLocal<UserInfo> userInfoThreadLocal = new ThreadLocal()` 初始化了一个Threadlocal 对象，就是上图中说的Threadlocal 引用，这个引用指向堆中的ThreadLocal 对象；
* 然后我们调用`userInfoThreadLocal.set(userInfo)`
  * **Thread 类有个 ThreadLocalMap 成员变量，这个Map key是Threadlocal 对象，value是你要存放的线程局部变量**
  * ThreadLocalMap 的key是ThreadLocal对象，value是线程隔离的变量

ThreadLocalMap同样是与HashMap一样使用的数组的数据结构

发生hash冲突的时候采用的是开放定址法，往后找到有空位的地方

**ThreadLocalMap的key采用的是WeakReference类型，并且为何设计成弱引用**

* 避免线程泄露

* hreadLocal<UserInfo> userInfoThreadLocal = new ThreadLocal<>();这是一个强引用，ThreadLocal对象同时也被ThreadlocalMap的key引用，这是个WeakReference引用GC要回收ThreadLocal对象的前提是它只被WeakReference引用，没有任何强引用

* ```java
  static class Entry extends WeakReference<ThreadLocal<?>> {
      Object value;
  
      Entry(ThreadLocal<?> k, Object v) {
          super(k);
          this.value = v;
      }
  }
  ```

  作为弱引用调用了super(k)(WeakReference)，因此虽然使用ThreadLocal作为Map的key，但是并不真正持有ThreadLocal的引用。当ThreadLocal的外部强引用被回收时，ThreadLocalMap的key变为null。

* **ThreadLocal对象有强引用，回收不掉，为何还要设计成WeakReference类型**

  * ThreadLocal的设计者考虑到线程往往生命周期很长，比如经常会用到线程池，线程一直存活着，根据JVM 根搜索算法，一直存在 Thread -> ThreadLocalMap -> Entry（元素）这样一条引用链路, 如下图，如果key不设计成WeakReference类型，是强引用的话，就一直不会被GC回收，key就一直不会是null，不为null Entry元素就不会被清理（ThreadLocalMap是根据key是否为null来判断是否清理Entry）
  * ThreadLocal的设计者认为只要ThreadLocal 所在的作用域结束了工作被清理了，GC回收的时候就会把key引用对象回收，key置为null，ThreadLocal会尽力保证Entry清理掉来最大可能避免内存泄漏
  * Threadlocal 对象一直有强引用，则调用remove函数避免内存泄露风险。

### java中的引用

* 强引用：一个对象具有强引用，那**垃圾回收器**绝不会回收它，当**内存空间不足**时，`Java`虚拟机宁愿抛出`OutOfMemoryError`错误，使程序**异常终止**，也不会靠随意**回收**具有**强引用**的**对象**来解决内存不足的问题
* 软引用：如果一个对象只具有**软引用**，则**内存空间充足**时，**垃圾回收器**就**不会**回收它；如果**内存空间不足**了，就会**回收**这些对象的内存
* **弱引用**与**软引用**的区别在于：只具有**弱引用**的对象拥有**更短暂**的**生命周期**。在垃圾回收器线程扫描内存区域时，一旦发现了只具有**弱引用**的对象，不管当前**内存空间足够与否**，都会**回收**它的内存。不过，由于垃圾回收器是一个**优先级很低的线程**，因此**不一定**会**很快**发现那些只具有**弱引用**的对象
* **虚引用**顾名思义，就是**形同虚设**。与其他几种引用都不同，**虚引用**并**不会**决定对象的**生命周期**。如果一个对象**仅持有虚引用**，那么它就和**没有任何引用**一样，在任何时候都可能被垃圾回收器回收



### 实现线程隔离

![Threadlocal-1](\images\Threadlocal-1.png)

## 无锁

**一种乐观的并发策略**

### CAS

CAS(V,E,N)

* V表示要更新的变量
* E表示预期值
* N表示新值
* 只有V与E的值相同的时候，才会将V的值设置为N
* V与E的值不相同，什么都不做，最后CAS返回当前V的真实值

#### CAS的不足

CAS是通过判断当前和期望值是否相同才进行写入

但是可能出现这种情况：

​	我打了一杯水，我去上厕所，中途有人把我的水喝了，又给我接上水，此时并不知道我的水杯是否被人喝过，然后我自己把水喝了。

经过两次修改，对象的值又变为旧值，无法判断对象的值是否给修改过。

### 线程安全整数AtomicInteger

可变并且线程安全的，修改等操作都是通过CAS命令进行的。

### Unsafe类

### AtomicReference

### AtomicStampedReference

这是一个带时间戳的对象引用

更新数据的时候，还必须更新时间戳

对象值以及时间戳都满足期望值，写入才会成功

**以此可以解决上述所说的CAS操作的不足**



### AtomicInterArray

可用的原子数组有：

* AtomicInterArray
* AtomicLongArray
* AtomicReferenceArray

### AtomicIntegerFieldUpdater

三种Updater：

* AtomicIntegerFieldUpdater
* AtomicLongFieldUpdater
* AtomicReferenceFieldUpdater

注意事项：

* Updater只能修改它课件范围内的变量，因为Updater通过反射得到这个变量。变量不可见就会出错。
* 为了确保变量被正确的读取，它必须是volatile类型的。
* 因为CAS操作会通过对象实例中的偏移量直接进行赋值，因此，它不支持static字段。

### 无锁的Vector实现

p171

## 死锁

### 概述

两个或者多个进程，互相占用对方需要的资源，并且都不进行释放，导致彼此都在等待对象释放资源，产生的一种无限等待现象。

死锁有多种解决方法

。。。。。。。



# 并行模式与算法

## 单例模式

* 对于频繁使用的对象，可以省略new操作花费的时间，尤其是对于一些重量级、常常用到的对象。
* 因为new的次数减少，对系统内存的使用频率也会降低，能够减轻GC的压力，缩短GC的停顿时间。

恶汉懒汉看设计模式



## 不变模式

并发情况下，多线程对同一个对象进行读写，为保证对象一致性和正确性，需要进行同步操作。

而不变模式呢，则是去除同步操作，从而提高并行程序的能力。

使用场景满足以下2个条件：

* **对象一旦被创建，内部状态永远都不会被改变**
* **对象需要被共享，被多线程频繁访问**

java中的不变模式实现

* 去除setter方法以及所有修改自身属性的方法
* final修饰类
* 将所有属性设置为私有，并且用final修饰(final保证是引用不会被改变，而不是引用的指向)，确保其不可被改变
* 确保没有子类可以重载修改它的行为
* 有一个可以创建完整对象的构造函数

源数据包装类都是基于不变模式实现的(Integer等等)

不变模式是通过回避问题而不是解决问题的态度来处理多线程并发访问控制。

因为不变模式不需要进行同步操作，所以能够提高系统的并发性和并发量

## 生产者-消费者模式

**案例p192**

生产者-消费者模式，有若干个**生产者线程**和若干个**消费者线程**组成。生产者线程负责提交用户请求，消费者线程负责具体处理生产者提交的任务。生产者和消费者之间则通过**共享内存缓冲区**进行通信。

生产者-消费者模式中的内存缓存区的主要功能是数据在多线程间的共享，并且能够通过缓冲区，缓解生产者与消费者间的性能差，从一定程度上缓解了性能瓶颈对系统性能的影响

* 生产者：用于提交用户请求，提取用户任务，并装入内存缓冲区
* 消费者：在内存缓冲区中提取并处理任务
* 内存缓冲区：缓存生产者提交的任务或数据，供消费者使用
* 任务：生产者向内存缓冲区提交的数据结构
* Main：使用生产者和消费者的客户端

![生产者-消费者模型](\images\生产者-消费者模型.PNG)



## 生产者-消费者(无锁)

BlockingQueue通过使用锁和阻塞来实现线程间的同步，在高并发的场合下，性能不够出众

可以使用ConcurrentLinkedQueue(内部通过了大量的CAS操作)来取代BlockingQueue

### 无锁缓存框架Disruptor

**案例p196**

* 使用环形队列代替普通线性队列
  * 与其它普通队列相比：
    * 普通队列需要提供队列同步head和尾部tail两个指针
    * 环形队列只需要对外提供当前位置的cursor，利用这个指针进行出队和入队操作
* 环形队列不能够动态扩展，大小需要事先进行设置，为2的整数次方
  * 设置为2的整数次方，能通过色quence&(queueSize-1)定位到实际的元素位置index，相比取余(%)操作要快
* 固定大小的环形队列能够做到完全的内存复用，系统运行非过程，不会有新的空间需要分配或者老的空间需要回收，减少系统分配空间产生开销
* 生产者写入数据与消费者读取数据都使用CAS操作来保护数据

![disruptor环形队列](\images\disruptor环形队列.PNG)



### 提高消费者响应时间

选择合适的策略

Disruptor提供了几种策略，让消费者能够监控缓冲区的信息。

这些策略使用WaitStrategy封装：

* BlockingWaitStrategy：默认策略。与BlockingQueue相似，使用锁与条件Condition进行数据的监控和线程的唤醒。最节省CPU，但是高并发情况下不太行。
* SleepingWaitStrategy：是一个对CPU使用保守的策略。在循环中不断等待数据。首先进行自旋等待(retries默认200，但是轮训100次后就阻塞)，获取不成功则调用Thread.yield()，当count为0时，最后调用LockSupport.parkNanos(sleepTimeNs);进行线程休眠。对数据处理可能会产生较高的平均延时。比较适合对延迟要求不是特别多的场合，**对生产者线程影响最小。**常见应用场景是异步日志。
* YieldingWaitStrategy：**用于低延迟的场合**，消费者线程不断循环(counter默认为100)监控缓冲区的变化，同时使用Thread.yield()让出cpu执行时间。逻辑cpu(线程)大于消费者线程。
  * 内部变成一个执行了Thread.yield()的死循环。
* BusySpinWaitStrategy：完全是一个死循环，消费者线程一直监控缓冲区的变化，消耗所有的cpu资源。物理cpu(核心)大于消费者线程数。

### CPU Cache的优化：解决伪共享

#### 伪共享概述

Disruptor解决伪共享

伪共享：为了提高CPU的速度，CPU有一个高速缓存Cache。在高速缓存中，读写数据的最小单位为缓存行，它是从主存复制到缓存的最小单位，一般为32字节到128字节。

两个变量存放在一个缓存行中，在多线程访问，可能会互相影响彼此的性能。如下：

* X和Y在同一个缓存行当中。
* 运行在CPU1上的线程更新了X，则CPU2上的缓存行就会失效，同一行的Y即使没有修改也会变成无效，导致缓存Cache无法命中。
* 如果在CPU2上的线程更新了Y，则导致CPU1上的缓存行又失效。
* 所以如果不能很好的命中缓存，会使系统的吞吐量急剧下降。

![disruptor-解决伪共享1](\images\disruptor-解决伪共享1.PNG)

**解决方案：**

* 在X变量的前后空间都先占据一定的位置
* 当内存被读入缓存中时，该缓存行，只有X一个变量实际是有效的，因此就不会发生多个线程同时修改行中不同变量而导致变量全体失效的情况。
* **案例见p202**

![disruptor-解决伪共享1](\images\disruptor-解决伪共享2.PNG)



## Future模式

Future模式是多线程开发中常见的一种设计模式，核心思想是异步调用。

### 见P204开始



## 并行流水线

### 见p212

## 并行搜索

### 见p216

## 并行排序

### 见p218

## 并行算法：矩阵乘法

### 见p226

## 网络NIO

### 见p230

## AIO

见p245

# Java8与并发

## p251

